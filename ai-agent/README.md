# AI Agent 开发工程师岗位考核（偏后端 / 智能体工程）

## 1. 考核背景

假设你加入一个小型团队，需要在极短时间内交付一个 **可运行、可验证的 AI Agent 服务 MVP**，用于支持团队内部与外部试点用户：

* **内部场景**：对公司文档/知识库问答、规范查询、常见流程指引
* **外部场景**：面向客户的“产品助手”，能基于知识库回答问题，并执行有限的工具动作（例如创建工单、查询订单/FAQ）

你的角色是：**AI Agent 开发工程师（后端为主）**。

你的目标不是堆砌功能，而是用可复用的工程化方式证明：

* Agent 能跑起来（稳定、可观测、可迭代）
* LLM 能被可靠集成（参数/提示词/工具/上下文可控）
* RAG 能有效提升回答命中率（并能解释其局限）
* 系统具备向“生产化”演进的基础（部署、扩展、成本意识）


## 2. 任务目标

实现一个 **可运行的 AI Agent Web 服务 MVP**，并在 README 中清晰说明你的决策逻辑与取舍。

技术栈不做强制要求，但期望你能覆盖岗位核心技能点：

* Python Web 开发（建议 FastAPI / Django）
* 主流 Agent 框架（例如 LangChain / AutoGPT / BabyAGI 或同类方案）
* Docker 化部署（最好提供 docker-compose）
* LLM 集成与可配置/可调优能力（模型、温度、上下文、工具策略等）
* 分布式系统的拆分思路（哪怕不完全落地，也要说明边界与演进路线）
* RAG 架构与向量数据库使用（可选用 Chroma / FAISS / pgvector / Milvus 等）


## 3. 功能要求

### ✅ 必须完成（核心）

1. **可运行的 Python Web 服务**
   * 提供 HTTP API（REST 或 WebSocket 均可）
   * 至少包含：健康检查接口、对话接口
   * 提供清晰的本地运行方式（含依赖安装、环境变量示例）

2. **基础用户体系（可极简）**
   * 注册 / 登录（允许简化实现）
   * 支持区分不同用户的会话与数据
   * 不要求安全级别达到生产标准，但要说明风险点（例如明文存储、弱口令等）

3. **LLM 集成与可配置**
   * 可对接任意主流大模型 API（OpenAI / Azure / 国内模型 / 本地模型均可）
   * 关键参数可配置（例如模型名、温度、最大 token、超时、重试）
   * 说明你对“可控输出”的策略（提示词约束、结构化输出、工具调用边界等）

4. **Agent 能力（必须体现“工具化”）**
   * 使用任意 Agent 框架或自研最小 Agent 也可
   * 至少实现 2 类工具（Tool）：
     * **知识库检索工具（RAG Search）**
     * **一个业务动作工具**（例如：创建工单、写入待办、查询模拟数据、调用一个简单内部 API）
   * 交付中需说明：工具选择、调用策略、失败兜底、权限边界（例如避免越权执行）

5. **RAG：向量检索与知识库构建**
   * 提供最小可用的知识库数据源（可用仓库内的示例文档/FAQ）
   * 提供数据入库/索引构建方式（脚本或启动时自动构建均可）
   * 至少保存：文档来源、分段策略、embedding 模型选择
   * 在 README 中说明：你如何评估 RAG 效果，以及可能的幻觉/召回不足问题

6. **对话记录与执行轨迹持久化**
   * 至少保存：用户、时间、消息内容
   * 建议额外保存：工具调用记录（输入/输出/耗时/错误）、模型响应元信息（token 或成本估算如有）
   * 可使用任意数据库或文件方案（SQLite/PostgreSQL/JSONL 等均可）

7. **Docker 化部署**
   * 提供 Dockerfile（能一键构建与运行）
   * 如包含数据库/向量库等依赖，建议提供 docker-compose
   * 明确环境变量与配置入口（不要把密钥写入仓库）

8. **README 说明（非常重要）**
   请在 README 中回答以下问题：
   * 这个 Agent 产品的定位是什么？目标用户是谁？成功指标是什么？
   * 你为什么选择当前技术方案（Web 框架、Agent 框架、向量库、数据存储）？
   * 你做了哪些取舍，哪些功能你选择不做？为什么？
   * 当前方案的主要风险或限制是什么（可靠性、安全、成本、效果、可扩展性）？
   * 如果这是一个真实产品，接下来 2 周你会如何迭代（按优先级列出 5～8 条）？


### ⭐ 可选加分项（非必须）

* **分布式拆分落地**：API 服务 + Worker（例如 Celery/RQ/自研队列），支持异步工具执行
* **可观测性**：结构化日志、trace_id、关键指标（延迟、错误率、token/成本）
* **上下文控制策略**：会话摘要、检索增强的上下文拼接策略、长对话降本方案
* **Prompt / Tool 设计说明**：提示词模板、工具描述、权限与安全边界
* **评测与回归**：最小测试集、离线评测脚本、RAG 命中/引用质量衡量
* **多租户/多知识库**：不同用户或组织级别的知识隔离与权限控制
* **向量库选型对比**：为什么选它、迁移/扩展路径、成本与运维影响

> 请注意：可选项不做不会扣分；盲目堆功能反而可能减分。


## 4. 交付要求

请在 PR 中至少包含：

* 可运行的服务代码
* 一份可复现的运行说明（本地运行 + Docker 运行）
* 至少一个示例知识库数据源与构建方式
* README 中的关键决策说明与取舍

并在 PR 描述中说明：

* 你大概投入了多少时间
* 你完成了哪些核心能力
* 哪些地方是“如果时间更多会继续优化的”


## 5. 我们重点关注什么？

* 你是否具备扎实的 Python Web 工程能力（结构、可维护性、边界清晰）
* 你是否理解并能工程化落地 Agent（工具、记忆、上下文、失败处理）
* 你是否真正理解 RAG 的收益与局限（召回、切分、引用、幻觉控制）
* 你对 LLM 集成的可靠性与成本是否有意识（超时、重试、限流、token）
* 你是否能给出合理的“分布式演进路线”（拆分边界、队列、幂等、可观测）

